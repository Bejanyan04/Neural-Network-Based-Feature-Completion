{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "16730028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import wasserstein_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09725f7",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "a58d861f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class DataPreprocessing():\n",
    "    def __init__(self,data,weigths):\n",
    "        self.CLIP_MIN = 13 # const values to indicate max and min of clipping\n",
    "        self.CLIP_MAX = 90\n",
    "        self.SCALE_PARAM =3.5\n",
    "        self.dataframe = data \n",
    "        self.weights = weigths\n",
    "        self.unscaled_y_train = 0\n",
    "        self.unscaled_y_test = 0\n",
    "        self.train_mean = 0 # mean value of training data :163 columns\n",
    "        self.group_count  = 0\n",
    "        \n",
    "    def UpdateWeights(self):\n",
    "        \"\"\"Add weights for the last three columns of the dataframe\"\"\"\n",
    "        self.weights = pd.concat([self.weights,pd.Series([1,1,1])],ignore_index=True)\n",
    "        \n",
    "    def CorrectOutliers(self):\n",
    "        \"\"\"Handle outliers existing in some columns\"\"\"\n",
    "        \n",
    "        self.dataframe['A'] = self.dataframe['A'].clip(self.CLIP_MIN,self.CLIP_MAX)\n",
    "        \n",
    "    def EncodeStrings(self):\n",
    "        \"\"\"Encode string values of column C to numeric values in range [-1,1]\"\"\"\n",
    "        \n",
    "        encoding = np.linspace(-1,1,160)\n",
    "        mappings = dict(zip(self.dataframe['C'].unique(), encoding))\n",
    "        self.dataframe['C'] = self.dataframe['C'].map(mappings)\n",
    "      \n",
    "    def MultiplyWeights(self):\n",
    "        \"\"\"Multiply columns with their weights\"\"\"\n",
    "    \n",
    "        self.dataframe = self.dataframe.mul(np.array(self.weights).reshape(1,-1), axis = 1).copy()\n",
    "  \n",
    "    def RandomChoice(self):\n",
    "        \"\"\"Choose random 30 column indices and concatenate last three column indices\"\"\"\n",
    "    \n",
    "        return np.concatenate((np.random.choice([i for i in range(163)],30, replace=False),[163,164,165]))\n",
    "    \n",
    "        \n",
    "    def SplitData(self,train_size=0.8):\n",
    "        \"\"\"Split unscaled data to train, test, and save unscaled values of train and test data \n",
    "        in purpose of using them during Ai model testing step\"\"\"\n",
    "       \n",
    "        train_data, test_data=  train_test_split(self.dataframe,train_size=train_size) ##166 columns\n",
    "        self.unscaled_y_train = train_data.iloc[:,:-3].copy() \n",
    "        self.unscaled_y_test = test_data.iloc[:,:-3].copy()  \n",
    "        return train_data,test_data\n",
    "    \n",
    "    def SaveTrainMean(self,train_data):\n",
    "        self.train_mean = (train_data.iloc[:,:-3].mean()).values\n",
    "        \n",
    "    def NormalizeData(self,data):\n",
    "        \"\"\"Normalize data to [-1,1]\"\"\"\n",
    "        data = data.copy()\n",
    "        if data.shape[1]== self.dataframe.shape[1]:  # normlization for input data(containing 166 features)\n",
    "            data.loc[:,'G'].replace({0:1, 1:-1, 2:0, 3:1}, inplace=True)\n",
    "            data.loc[:,'A']  = 2*((data.loc[:,'A']-self.CLIP_MIN)/(self.CLIP_MAX-self.CLIP_MIN))-1\n",
    "            data.iloc[:,:-3] = (data.iloc[:,:-3] - self.train_mean) / self.SCALE_PARAM\n",
    "        else:\n",
    "            data =(data - self.train_mean) / self.SCALE_PARAM #normalization for output  data (163 features)\n",
    "        return data\n",
    " \n",
    "    def GetAiInput(self,scaled_train_data,scaled_test_data,indices):\n",
    "      #  Take 30, take 166 mean vector, put 30 into 163 , put into 164-166,\n",
    "       # then we have here updated mean vector (not all mean anymore)\"\"\"\n",
    "        \n",
    "        col_indices = self.dataframe.columns[indices]\n",
    "        means = scaled_train_data.mean() # mean of 166 cols, to create numpy array filled with that means\n",
    "        new_train = np.zeros(scaled_train_data.shape)\n",
    "        new_test = np.zeros(scaled_test_data.shape)\n",
    "        new_test[:,indices] = scaled_test_data[col_indices] # fill 33 columns of mean vector of actual values\n",
    "        \n",
    "        new_train[:,indices] = scaled_train_data[col_indices]\n",
    "        \n",
    "        #get uncaled input and output  normalized train and test data(type=dataframe)\n",
    "        self.x_train = pd.DataFrame(new_train, columns = self.dataframe.columns)\n",
    "        self.x_test = pd.DataFrame(new_test,columns = self.dataframe.columns)\n",
    "        self.y_train = scaled_train_data.iloc[:,:-3].copy() \n",
    "        self.y_test = scaled_test_data.iloc[:,:-3].copy()  #tarrget output (163 features)\n",
    "        return self.x_train,self.x_test,self.y_train,self.y_test\n",
    "    \n",
    "        \n",
    "    def GroupNumber(self):\n",
    "        \"\"\"save size of each group\n",
    "        return indexing for spliting data with groups in training and testing of Ai model\"\"\"\n",
    "        first_letters = [i[0]for i in list(self.dataframe.iloc[:,:-3].columns)]\n",
    "        self.group_count = [first_letters.count(el) for el in np.unique(first_letters)]\n",
    "        return [sum(self.group_count[0:i]) for i in range (1,len(self.group_count))]\n",
    "\n",
    "    def CorrectData(self):\n",
    "        self.UpdateWeights()\n",
    "        self.CorrectOutliers()\n",
    "        self.EncodeStrings()\n",
    "        self.MultiplyWeights()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "8c088aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe =pd.read_csv(\"./intern_data/data.csv\") \n",
    "weights = pd.read_csv(\"./intern_data/weights.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "cc9c5711",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess= DataPreprocessing(dataframe,weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "98462e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = preprocess.RandomChoice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "086d4248",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess.CorrectData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "f790e26a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>...</th>\n",
       "      <th>P4</th>\n",
       "      <th>P5</th>\n",
       "      <th>P6</th>\n",
       "      <th>P7</th>\n",
       "      <th>P8</th>\n",
       "      <th>P9</th>\n",
       "      <th>P10</th>\n",
       "      <th>A</th>\n",
       "      <th>G</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44638</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-2</td>\n",
       "      <td>-4</td>\n",
       "      <td>-3</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.823899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40002</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-4</td>\n",
       "      <td>-5</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26361</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-4</td>\n",
       "      <td>-3</td>\n",
       "      <td>-4</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23496</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-4</td>\n",
       "      <td>-5</td>\n",
       "      <td>-4</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18111</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-4</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.597484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48401</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>-3</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-3</td>\n",
       "      <td>-4</td>\n",
       "      <td>-3</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46617</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-2</td>\n",
       "      <td>-3</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-4</td>\n",
       "      <td>-2</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10490</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>-3</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.886792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14869</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-4</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42246</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>-4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "      <td>-4</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39327 rows × 166 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       A1  A2  A3  A4  A5  A6  A7  A8  A9  A10  ...  P4  P5  P6  P7  P8  P9  \\\n",
       "44638   3   4   4   4   2   2   4  -2  -2   -4  ...   4   4   3   3  -2  -4   \n",
       "40002   5   5   5   5   4   4   5  -2  -1   -1  ...   2   1   5   3  -3  -4   \n",
       "26361   4   4   4   3   5   4   4  -3  -3   -1  ...   2   2   4   2  -4  -3   \n",
       "23496   4   4   5   4   4   4   4  -2  -1   -3  ...   2   3   4   2  -4  -5   \n",
       "18111   2   3   4   3   4   3   2  -4  -3   -3  ...   4   2   3   3  -3  -4   \n",
       "...    ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ..  ..  ..  ..  ..  ..   \n",
       "48401   4   4   4   4   4   3   5  -3  -2   -1  ...   3   2   2   1  -3  -4   \n",
       "46617   5   3   5   3   4   4   3  -3  -2   -3  ...   5   3   4   4  -1  -4   \n",
       "10490   4   5   4   4   5   4   5  -3  -2   -2  ...   2   2   2   4  -4  -4   \n",
       "14869   5   5   4   4   5   5   4  -3  -1   -1  ...   4   2   3   2  -3  -3   \n",
       "42246   4   4   4   3   5   3   4  -3  -3   -4  ...   3   2   4   5  -1  -3   \n",
       "\n",
       "       P10   A  G         C  \n",
       "44638   -3  19  2 -0.823899  \n",
       "40002   -5  39  2 -1.000000  \n",
       "26361   -4  19  2 -1.000000  \n",
       "23496   -4  23  2 -1.000000  \n",
       "18111   -4  18  2 -0.597484  \n",
       "...    ...  .. ..       ...  \n",
       "48401   -3  25  2 -1.000000  \n",
       "46617   -2  16  2 -1.000000  \n",
       "10490   -4  59  1 -0.886792  \n",
       "14869   -4  28  1 -1.000000  \n",
       "42246   -4  18  2 -1.000000  \n",
       "\n",
       "[39327 rows x 166 columns]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data = preprocess.SplitData()\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "a3138bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train = preprocess.NormalizeData(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "38269a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>...</th>\n",
       "      <th>P4</th>\n",
       "      <th>P5</th>\n",
       "      <th>P6</th>\n",
       "      <th>P7</th>\n",
       "      <th>P8</th>\n",
       "      <th>P9</th>\n",
       "      <th>P10</th>\n",
       "      <th>A</th>\n",
       "      <th>G</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44638</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>-0.571429</td>\n",
       "      <td>-0.571429</td>\n",
       "      <td>-1.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>-0.571429</td>\n",
       "      <td>-1.142857</td>\n",
       "      <td>-0.857143</td>\n",
       "      <td>-0.844156</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.823899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40002</th>\n",
       "      <td>1.428571</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>-0.571429</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>-0.857143</td>\n",
       "      <td>-1.142857</td>\n",
       "      <td>-1.428571</td>\n",
       "      <td>-0.324675</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26361</th>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>-0.857143</td>\n",
       "      <td>-0.857143</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>-1.142857</td>\n",
       "      <td>-0.857143</td>\n",
       "      <td>-1.142857</td>\n",
       "      <td>-0.844156</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23496</th>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>-0.571429</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>-0.857143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>-1.142857</td>\n",
       "      <td>-1.428571</td>\n",
       "      <td>-1.142857</td>\n",
       "      <td>-0.740260</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18111</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>-1.142857</td>\n",
       "      <td>-0.857143</td>\n",
       "      <td>-0.857143</td>\n",
       "      <td>...</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>-0.857143</td>\n",
       "      <td>-1.142857</td>\n",
       "      <td>-1.142857</td>\n",
       "      <td>-0.870130</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.597484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48401</th>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>-0.857143</td>\n",
       "      <td>-0.571429</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>-0.857143</td>\n",
       "      <td>-1.142857</td>\n",
       "      <td>-0.857143</td>\n",
       "      <td>-0.688312</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46617</th>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>-0.857143</td>\n",
       "      <td>-0.571429</td>\n",
       "      <td>-0.857143</td>\n",
       "      <td>...</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>-1.142857</td>\n",
       "      <td>-0.571429</td>\n",
       "      <td>-0.922078</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10490</th>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>-0.857143</td>\n",
       "      <td>-0.571429</td>\n",
       "      <td>-0.571429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>-1.142857</td>\n",
       "      <td>-1.142857</td>\n",
       "      <td>-1.142857</td>\n",
       "      <td>0.194805</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.886792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14869</th>\n",
       "      <td>1.428571</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>-0.857143</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>...</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>-0.857143</td>\n",
       "      <td>-0.857143</td>\n",
       "      <td>-1.142857</td>\n",
       "      <td>-0.610390</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42246</th>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>-0.857143</td>\n",
       "      <td>-0.857143</td>\n",
       "      <td>-1.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>-0.857143</td>\n",
       "      <td>-1.142857</td>\n",
       "      <td>-0.870130</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39327 rows × 166 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             A1        A2        A3        A4        A5        A6        A7  \\\n",
       "44638  0.857143  1.142857  1.142857  1.142857  0.571429  0.571429  1.142857   \n",
       "40002  1.428571  1.428571  1.428571  1.428571  1.142857  1.142857  1.428571   \n",
       "26361  1.142857  1.142857  1.142857  0.857143  1.428571  1.142857  1.142857   \n",
       "23496  1.142857  1.142857  1.428571  1.142857  1.142857  1.142857  1.142857   \n",
       "18111  0.571429  0.857143  1.142857  0.857143  1.142857  0.857143  0.571429   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "48401  1.142857  1.142857  1.142857  1.142857  1.142857  0.857143  1.428571   \n",
       "46617  1.428571  0.857143  1.428571  0.857143  1.142857  1.142857  0.857143   \n",
       "10490  1.142857  1.428571  1.142857  1.142857  1.428571  1.142857  1.428571   \n",
       "14869  1.428571  1.428571  1.142857  1.142857  1.428571  1.428571  1.142857   \n",
       "42246  1.142857  1.142857  1.142857  0.857143  1.428571  0.857143  1.142857   \n",
       "\n",
       "             A8        A9       A10  ...        P4        P5        P6  \\\n",
       "44638 -0.571429 -0.571429 -1.142857  ...  1.142857  1.142857  0.857143   \n",
       "40002 -0.571429 -0.285714 -0.285714  ...  0.571429  0.285714  1.428571   \n",
       "26361 -0.857143 -0.857143 -0.285714  ...  0.571429  0.571429  1.142857   \n",
       "23496 -0.571429 -0.285714 -0.857143  ...  0.571429  0.857143  1.142857   \n",
       "18111 -1.142857 -0.857143 -0.857143  ...  1.142857  0.571429  0.857143   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "48401 -0.857143 -0.571429 -0.285714  ...  0.857143  0.571429  0.571429   \n",
       "46617 -0.857143 -0.571429 -0.857143  ...  1.428571  0.857143  1.142857   \n",
       "10490 -0.857143 -0.571429 -0.571429  ...  0.571429  0.571429  0.571429   \n",
       "14869 -0.857143 -0.285714 -0.285714  ...  1.142857  0.571429  0.857143   \n",
       "42246 -0.857143 -0.857143 -1.142857  ...  0.857143  0.571429  1.142857   \n",
       "\n",
       "             P7        P8        P9       P10         A  G         C  \n",
       "44638  0.857143 -0.571429 -1.142857 -0.857143 -0.844156  0 -0.823899  \n",
       "40002  0.857143 -0.857143 -1.142857 -1.428571 -0.324675  0 -1.000000  \n",
       "26361  0.571429 -1.142857 -0.857143 -1.142857 -0.844156  0 -1.000000  \n",
       "23496  0.571429 -1.142857 -1.428571 -1.142857 -0.740260  0 -1.000000  \n",
       "18111  0.857143 -0.857143 -1.142857 -1.142857 -0.870130  0 -0.597484  \n",
       "...         ...       ...       ...       ...       ... ..       ...  \n",
       "48401  0.285714 -0.857143 -1.142857 -0.857143 -0.688312  0 -1.000000  \n",
       "46617  1.142857 -0.285714 -1.142857 -0.571429 -0.922078  0 -1.000000  \n",
       "10490  1.142857 -1.142857 -1.142857 -1.142857  0.194805 -1 -0.886792  \n",
       "14869  0.571429 -0.857143 -0.857143 -1.142857 -0.610390 -1 -1.000000  \n",
       "42246  1.428571 -0.285714 -0.857143 -1.142857 -0.870130  0 -1.000000  \n",
       "\n",
       "[39327 rows x 166 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "8901f026",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_test = preprocess.NormalizeData(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14b12e7",
   "metadata": {},
   "source": [
    "# Separate Ai input and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "1f0c78ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = preprocess.GetAiInput(scaled_train,scaled_test,indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed375a75",
   "metadata": {},
   "source": [
    "# Denoising Autoencoder based architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad75dd7a",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6b6b23f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X_train, Y_train):\n",
    "        x = X_train.values\n",
    "        y = Y_train.values\n",
    "        self.x_train= torch.from_numpy(x).float()\n",
    "        self.y_train= torch.from_numpy(y).float()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y_train)\n",
    "   \n",
    "    def __getitem__(self,idx):\n",
    "        return self.x_train[idx].float(), self.y_train[idx].float()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6139436f",
   "metadata": {},
   "source": [
    "# Model training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6d267dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "   def TrainNN(train_loader,num_epochs,loss_function):\n",
    "        for epoch in range(num_epochs):\n",
    "            acc=0\n",
    "            print(\"Epoch: \" + str(epoch))\n",
    "            epoch_loss = 0\n",
    "            for i, (data, targets) in enumerate(train_loader):\n",
    "                predictions = model(data)\n",
    "                loss = loss_function(predictions, targets)\n",
    "                epoch_loss += loss\n",
    "                #Backward\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            print(\"loss: \",epoch_loss/i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507d9e42",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "db401057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuarcy computed for whole dataset\n",
    "def CheckAccuracy(model,input_scaled,target_unscaled):\n",
    "    input_scaled = torch.from_numpy(input_scaled.values).float().unsqueeze(1)\n",
    "    target_unscaled = torch.from_numpy(target_unscaled.values).float()\n",
    "    with torch.no_grad():\n",
    "        pred_scaled = model(input_scaled)\n",
    "    prediction_float = (pred_scaled * 3.5) + preprocess.train_mean\n",
    "    prediction_int = torch.round(prediction_float)\n",
    "    prediction_int = torch.reshape(prediction_int,(prediction_int.shape[0],prediction_int.shape[-1]))\n",
    "    equality_matrix = (prediction_int==target_unscaled)\n",
    "    num_correct = equality_matrix.sum()\n",
    "    num_samples = (equality_matrix.shape[0]*equality_matrix.shape[-1])\n",
    "    print(f'Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples):.5f}') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21df9886",
   "metadata": {},
   "source": [
    "# With dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "dd67f55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DAE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DAE,self).__init__()\n",
    "        self.encoder = torch.nn.Sequential (\n",
    "        torch.nn.Linear(166, 128),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(128, 64),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(64, 36),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(36, 18),\n",
    "        torch.nn.LeakyReLU(),\n",
    "        torch.nn.Linear(18, 9))\n",
    "        self.decoder = torch.nn.Sequential (\n",
    "        torch.nn.Linear(9, 18),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(18, 36),\n",
    "        torch.nn.LeakyReLU(),\n",
    "        torch.nn.Linear(36, 64),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(64, 128),\n",
    "        torch.nn.LeakyReLU(),\n",
    "        torch.nn.Linear(128, 163))\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "eace9d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DAE()\n",
    "loss_function = nn.MSELoss()\n",
    "#loss_function = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate) \n",
    "batch_size = 30\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "02c3209c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "loss:  tensor(0.1046, grad_fn=<DivBackward0>)\n",
      "Epoch: 1\n",
      "loss:  tensor(0.0864, grad_fn=<DivBackward0>)\n",
      "Epoch: 2\n",
      "loss:  tensor(0.0851, grad_fn=<DivBackward0>)\n",
      "Epoch: 3\n",
      "loss:  tensor(0.0836, grad_fn=<DivBackward0>)\n",
      "Epoch: 4\n",
      "loss:  tensor(0.0789, grad_fn=<DivBackward0>)\n",
      "Epoch: 5\n",
      "loss:  tensor(0.0774, grad_fn=<DivBackward0>)\n",
      "Epoch: 6\n",
      "loss:  tensor(0.0760, grad_fn=<DivBackward0>)\n",
      "Epoch: 7\n",
      "loss:  tensor(0.0752, grad_fn=<DivBackward0>)\n",
      "Epoch: 8\n",
      "loss:  tensor(0.0750, grad_fn=<DivBackward0>)\n",
      "Epoch: 9\n",
      "loss:  tensor(0.0748, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "TrainNN(train_loader,num_epochs,loss_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "952fbdf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 708632 / 6410301 with accuracy 0.11055\n"
     ]
    }
   ],
   "source": [
    "CheckAccuracy(model,x_train,preprocess.unscaled_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "418ce047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 178795 / 1602616 with accuracy 0.11156\n"
     ]
    }
   ],
   "source": [
    "CheckAccuracy(model,x_test,preprocess.unscaled_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9fc33e",
   "metadata": {},
   "source": [
    "# residual network for CNNI inputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "173c7578",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convolution 1D\n",
    "class ResidualNet(nn.Module): \n",
    "    def __init__(self):  \n",
    "        super(ResidualNet, self).__init__()\n",
    "\n",
    "        self.conv1 = torch.nn.Conv1d(in_channels=1, out_channels=1, kernel_size=10, stride=1,\n",
    "                        padding=0, dilation=1, groups=1, bias=True, \n",
    "                        padding_mode='replicate', device=None, dtype=None)\n",
    "        \n",
    "        self.max_pool1 = torch.nn.AvgPool1d(kernel_size=3, stride=None, padding=0, ceil_mode=False, count_include_pad=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(in_channels=1, out_channels=10, kernel_size=3, stride=1,\n",
    "                        padding=0, dilation=1, groups=1, bias=True, \n",
    "                        padding_mode='reflect', device=None, dtype=None)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(in_channels=10, out_channels=20, kernel_size=3, stride=1,\n",
    "                        padding=0, dilation=1, groups=1, bias=True, \n",
    "                        padding_mode='reflect', device=None, dtype=None)\n",
    "        \n",
    "        self.conv4 = nn.Conv1d(in_channels=20, out_channels=1, kernel_size=5, stride=1,\n",
    "                        padding=0, dilation=1, groups=1, bias=True, \n",
    "                        padding_mode='zeros', device=None, dtype=None)\n",
    "        self.conv5 = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=3, stride=1,\n",
    "                        padding=0, dilation=1, groups=1, bias=True, \n",
    "                        padding_mode='zeros', device=None, dtype=None)\n",
    "        \n",
    "        self.conv6 = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=5, stride=1,\n",
    "                        padding=0, dilation=1, groups=1, bias=True, \n",
    "                        padding_mode='zeros', device=None, dtype=None)\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.dense1 = nn.Linear(10,163)\n",
    "        self.dense2 = nn.Linear(100,163)\n",
    "        self.dense3 = nn.Linear(163,163)\n",
    "               \n",
    "    def forward(self,x):\n",
    "        res = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool1(x)\n",
    "        x= self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x= self.max_pool1(x)\n",
    "        x= self.relu(x)\n",
    "        x = self.conv4(x)\n",
    "        x= self.relu(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dense1(x)\n",
    "        x  = x + res[:,:,:163] \n",
    "        x = self.dense3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "00e43cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResidualNet()\n",
    "loss_function = nn.MSELoss()\n",
    "learning_rate = 0.001\n",
    "#optimizer = optim.Adam(model.parameters(), lr = learning_rate) \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) \n",
    "batch_size = 30\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "4254cd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "   def TrainRCNN(model,train_loader, num_epochs, loss_function):\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            acc=0\n",
    "            print(\"Epoch: \" + str(epoch))\n",
    "            epoch_loss = 0\n",
    "            for i, (data, targets) in enumerate(train_loader):\n",
    "                data = data.float().unsqueeze(1)\n",
    "                predictions = model(data)\n",
    "                targets = targets.unsqueeze(1)\n",
    "                loss = loss_function(predictions, targets)\n",
    "                epoch_loss += loss+ 1/(torch.log(loss))\n",
    "                #Backward\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            print(\"loss: \",epoch_loss/i)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "66872c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "loss:  tensor(-1.3105, grad_fn=<DivBackward0>)\n",
      "Epoch: 1\n",
      "loss:  tensor(-0.3325, grad_fn=<DivBackward0>)\n",
      "Epoch: 2\n",
      "loss:  tensor(-0.3286, grad_fn=<DivBackward0>)\n",
      "Epoch: 3\n",
      "loss:  tensor(-0.3254, grad_fn=<DivBackward0>)\n",
      "Epoch: 4\n",
      "loss:  tensor(-0.3227, grad_fn=<DivBackward0>)\n",
      "Epoch: 5\n",
      "loss:  tensor(-0.3203, grad_fn=<DivBackward0>)\n",
      "Epoch: 6\n",
      "loss:  tensor(-0.3183, grad_fn=<DivBackward0>)\n",
      "Epoch: 7\n",
      "loss:  tensor(-0.3166, grad_fn=<DivBackward0>)\n",
      "Epoch: 8\n",
      "loss:  tensor(-0.3151, grad_fn=<DivBackward0>)\n",
      "Epoch: 9\n",
      "loss:  tensor(-0.3138, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "TrainRCNN(model,train_loader,num_epochs,loss_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a46f16e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 837630 / 6410301 with accuracy 0.13067\n"
     ]
    }
   ],
   "source": [
    "CheckAccuracy(model,x_train,preprocess.unscaled_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d156a703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 209408 / 1602616 with accuracy 0.13067\n"
     ]
    }
   ],
   "source": [
    "CheckAccuracy(model,x_test,preprocess.unscaled_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a80ae69",
   "metadata": {},
   "source": [
    "# Contractive autoencoder based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "62bbd231",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CAE, self).__init__()\n",
    "\n",
    "        self.enc1 = nn.Linear(166, 120) # Encoder\n",
    "        self.enc2 = nn.Linear(120, 80) \n",
    "        self.enc3 = nn.Linear(80, 40) \n",
    "\n",
    "        self.dec1 = nn.Linear(40,80)\n",
    "        self.dec2 = nn.Linear(80,120)\n",
    "        self.dec3 = nn.Linear(120,166)\n",
    "        self.output = nn.Linear(166,163)\n",
    "\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "    def encoder(self, x):\n",
    "        x = self.enc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.enc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.enc3(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "    def decoder(self,z):\n",
    "        z = self.dec1(z)\n",
    "        z = self.relu(z)\n",
    "        z = self.dec2(z)\n",
    "        z = self.relu(z)\n",
    "        z = self.dec3(z)\n",
    "        z = self.relu(z)\n",
    "        z = self.output(z)\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "            h1 = self.encoder(x)\n",
    "            h2 = self.decoder(h1)\n",
    "            return h1, h2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "39f9a748",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CAE()\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate) \n",
    "batch_size = 30\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "dd012ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "   def TrainCAE(train_loader,num_epochs):\n",
    "        for epoch in range(num_epochs):\n",
    "            acc=0\n",
    "            print(\"Epoch: \" + str(epoch))\n",
    "            epoch_loss = 0\n",
    "            for i, (data, targets) in enumerate(train_loader):\n",
    "                output_enc,predictions = model(data)\n",
    "                cae_loss = torch.norm(torch.autograd.functional.jacobian(model.encoder, data, create_graph=True))\n",
    "                reconstruct_loss = loss_function(predictions,targets)\n",
    "                loss = cae_loss + reconstruct_loss\n",
    "                #Backward\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            print(\"loss: \",epoch_loss/i)\n",
    "            \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "bb9a8b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ds = MyDataset(x_train, y_train)\n",
    "train_loader=DataLoader(Ds,batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "94f6e79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "loss:  tensor(0.2252, grad_fn=<DivBackward0>)\n",
      "Epoch: 1\n",
      "loss:  tensor(0.1097, grad_fn=<DivBackward0>)\n",
      "Epoch: 2\n",
      "loss:  tensor(0.1095, grad_fn=<DivBackward0>)\n",
      "Epoch: 3\n",
      "loss:  tensor(0.1095, grad_fn=<DivBackward0>)\n",
      "Epoch: 4\n",
      "loss:  tensor(0.1094, grad_fn=<DivBackward0>)\n",
      "Epoch: 5\n",
      "loss:  tensor(0.1093, grad_fn=<DivBackward0>)\n",
      "Epoch: 6\n",
      "loss:  tensor(0.1093, grad_fn=<DivBackward0>)\n",
      "Epoch: 7\n",
      "loss:  tensor(0.1092, grad_fn=<DivBackward0>)\n",
      "Epoch: 8\n",
      "loss:  tensor(0.1092, grad_fn=<DivBackward0>)\n",
      "Epoch: 9\n",
      "loss:  tensor(0.1092, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "TrainCAE(train_loader,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "37a724c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 250450 / 6410301 with accuracy 0.03907\n"
     ]
    }
   ],
   "source": [
    "CheckAccuracy(model,x_train,preprocess.unscaled_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "0dbd6588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 59474 / 1602616 with accuracy 0.03711\n"
     ]
    }
   ],
   "source": [
    "CheckAccuracy(model,x_test,preprocess.unscaled_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fb3c56",
   "metadata": {},
   "source": [
    "# CNN based autoencoder model suggested on paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "526f2fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convolution 1D\n",
    "class CnnEncDec(nn.Module): \n",
    "    def __init__(self):  \n",
    "        super(CnnEncDec, self).__init__()\n",
    "\n",
    "        self.enc1 = torch.nn.Conv1d(in_channels=1, out_channels=30, kernel_size=10, stride=2,\n",
    "                        padding=0, dilation=1, groups=1, bias=True, \n",
    "                        padding_mode='zeros', device=None, dtype=None)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.enc2 = nn.Conv1d(in_channels=30, out_channels=15, kernel_size=10, stride=5,\n",
    "                        padding=0, dilation=1, groups=1, bias=True, \n",
    "                        padding_mode='zeros', device=None, dtype=None)\n",
    "        \n",
    "        self.enc3 = nn.Conv1d(in_channels=15, out_channels=8, kernel_size=10, stride=2,\n",
    "                        padding=0, dilation=1, groups=1, bias=True, \n",
    "                        padding_mode='zeros', device=None, dtype=None)\n",
    "\n",
    "        \n",
    "        self.softmax = nn.Softmax()\n",
    "        self.dense1 = nn.Linear(3,100)\n",
    "        self.dense2 = nn.Linear(100,163)\n",
    "        \n",
    "        self.dec1 = torch.nn.ConvTranspose1d(in_channels=8, out_channels=15, kernel_size=10, stride=2, padding=0, \n",
    "                                             output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros')\n",
    "            \n",
    "        self.dec2 = torch.nn.ConvTranspose1d(in_channels=15, out_channels=25, kernel_size=10, stride=5, padding=0, \n",
    "                                             output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros')\n",
    "        \n",
    "        self.dec3 = torch.nn.ConvTranspose1d(in_channels=25, out_channels=30, kernel_size=10, stride=2, padding=0, \n",
    "                                             output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros')\n",
    "        \n",
    "        self.dec4 = torch.nn.ConvTranspose1d(in_channels=30, out_channels=1, kernel_size=10, stride=1, padding=0, \n",
    "                                             output_padding=0, groups=1, bias=True, dilation=1, padding_mode='zeros')\n",
    "        self.dense3 = nn.Linear(3367,2000)\n",
    "        self.dense4 = nn.Linear(2000,1000)\n",
    "        self.dense5 =  nn.Linear(1000,163)\n",
    "                      \n",
    "            \n",
    "    def forward(self,x):\n",
    "        x= self.enc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.enc2(x)\n",
    "        x= self.relu(x)\n",
    "        x = self.enc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dec1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dec2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dec3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dec4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dense4(x) \n",
    "        x = self.relu(x)\n",
    "        x = self.dense5(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7618a8",
   "metadata": {},
   "source": [
    "# loss function = 10*log(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e623eef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "   def TrainCNN(train_loader,num_epochs,loss_function):\n",
    "        for epoch in range(num_epochs):\n",
    "            acc=0\n",
    "            print(\"Epoch: \" + str(epoch))\n",
    "            epoch_loss = 0\n",
    "            for i, (data, targets) in enumerate(train_loader):\n",
    "                data = data.float().unsqueeze(1)\n",
    "                predictions = model(data)\n",
    "                targets = targets.unsqueeze(1)\n",
    "                loss = loss_function(predictions, targets)\n",
    "                epoch_loss += 10*torch.log(loss)\n",
    "                #Backward\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            print(\"loss: \",epoch_loss/i)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d2b9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate) \n",
    "batch_size = 30\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "67b099f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "loss:  tensor(-25.7381, grad_fn=<DivBackward0>)\n",
      "Epoch: 1\n",
      "loss:  tensor(-25.9350, grad_fn=<DivBackward0>)\n",
      "Epoch: 2\n",
      "loss:  tensor(-26.0275, grad_fn=<DivBackward0>)\n",
      "Epoch: 3\n",
      "loss:  tensor(-26.0517, grad_fn=<DivBackward0>)\n",
      "Epoch: 4\n",
      "loss:  tensor(-26.0597, grad_fn=<DivBackward0>)\n",
      "Epoch: 5\n",
      "loss:  tensor(-26.0724, grad_fn=<DivBackward0>)\n",
      "Epoch: 6\n",
      "loss:  tensor(-26.0833, grad_fn=<DivBackward0>)\n",
      "Epoch: 7\n",
      "loss:  tensor(-26.0978, grad_fn=<DivBackward0>)\n",
      "Epoch: 8\n",
      "loss:  tensor(-26.1038, grad_fn=<DivBackward0>)\n",
      "Epoch: 9\n",
      "loss:  tensor(-26.1161, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "TrainCNN(train_loader,num_epochs,loss_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8cf4598c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 2694718 / 6410301 with accuracy 0.42037\n"
     ]
    }
   ],
   "source": [
    "CheckAccuracy(model,x_train,preprocess.unscaled_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "e35ae9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 250450 / 6410301 with accuracy 0.03907\n"
     ]
    }
   ],
   "source": [
    "CheckAccuracy(model,x_test,preprocess.unscaled_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8a5c53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
